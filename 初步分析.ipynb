{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import imblearn\n",
    "import numpy as np\n",
    "import traceback\n",
    "pd.set_option('display.max_rows', 20,'max_info_columns', 9999,'display.max_columns', 9999)\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing,metrics\n",
    "import datetime as dt\n",
    "import gc\n",
    "from sklearn import svm,linear_model\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder,Imputer\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor,VotingClassifier\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn import neighbors\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "import jieba #导入结巴分词\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import RFE \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.cross_validation import  cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "import xlrd\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 12, 30, 56, 90, 132, 182, 240, 306, 380, 462, 552, 650, 756, 870, 992, 1122, 1260, 1406, 1560, 1722, 1892, 2070, 2256, 2450, 2652, 2862, 3080, 3306, 3540, 3782, 4032, 4290, 4556, 4830, 5112, 5402, 5700, 6006, 6320, 6642, 6972, 7310, 7656, 8010, 8372, 8742, 9120, 9506, 9900]\n"
     ]
    }
   ],
   "source": [
    "print([x*(x+1) for x in range(1,100,2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('/home/tsl-yu/文档/云移杯/YNU.EDU2018-ScenicWord/train_first.csv')\n",
    "\n",
    "test=pd.read_csv('/home/tsl-yu/文档/云移杯/YNU.EDU2018-ScenicWord/predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Discuss</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201e8bf2-77a2-3a98-9fcf-4ce03914e712</td>\n",
       "      <td>好大的一个游乐公园，已经去了2次，但感觉还没有玩够似的！会有第三，第四次的</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f4d51947-eac4-3005-9d3c-2f32d6068a2d</td>\n",
       "      <td>新中国成立也是在这举行，对我们中国人来说有些重要及深刻的意义！</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74aa7ae4-03a4-394c-bee0-5702d3a3082a</td>\n",
       "      <td>庐山瀑布非常有名，也有非常多个瀑布，只是最好看的非三叠泉莫属，推荐一去</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>099661c2-4360-3c49-a2fe-8c783764f7db</td>\n",
       "      <td>个人觉得颐和园是北京最值的一起的地方，不过相比下门票也是最贵的，比起故宫的雄伟与气势磅礴，颐...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97ca672d-e558-3542-ba7b-ee719bba1bab</td>\n",
       "      <td>迪斯尼一日游</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id  \\\n",
       "0  201e8bf2-77a2-3a98-9fcf-4ce03914e712   \n",
       "1  f4d51947-eac4-3005-9d3c-2f32d6068a2d   \n",
       "2  74aa7ae4-03a4-394c-bee0-5702d3a3082a   \n",
       "3  099661c2-4360-3c49-a2fe-8c783764f7db   \n",
       "4  97ca672d-e558-3542-ba7b-ee719bba1bab   \n",
       "\n",
       "                                             Discuss  Score  \n",
       "0              好大的一个游乐公园，已经去了2次，但感觉还没有玩够似的！会有第三，第四次的      5  \n",
       "1                    新中国成立也是在这举行，对我们中国人来说有些重要及深刻的意义！      4  \n",
       "2                庐山瀑布非常有名，也有非常多个瀑布，只是最好看的非三叠泉莫属，推荐一去      4  \n",
       "3  个人觉得颐和园是北京最值的一起的地方，不过相比下门票也是最贵的，比起故宫的雄伟与气势磅礴，颐...      5  \n",
       "4                                             迪斯尼一日游      5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train['Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.826 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "cw = lambda x: list(jieba.cut(x)) #定义分词函数\n",
    "train['words'] = train['Discuss'].apply(cw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np_utils.to_categorical(train['Score']-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict['words'] = predict['Discuss'].apply(cw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 统计詞频 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_train = pd.concat([train['words'], predict['words']], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将所有词语整合在一起\n",
    "w = []\n",
    "for i in d2v_train:\n",
    "  w.extend(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = pd.DataFrame(pd.Series(w).value_counts()) #统计词的出现次数\n",
    "#del w,d2v_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict['id']=list(range(1,len(dict)+1))\n",
    "# dict = dict[(dict[0]>=10) & (dict[0] < 72410)]\n",
    "# print(dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>，</th>\n",
       "      <td>364269</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>的</th>\n",
       "      <td>210455</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>。</th>\n",
       "      <td>123441</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>72410</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>了</th>\n",
       "      <td>56857</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>是</th>\n",
       "      <td>54971</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>很</th>\n",
       "      <td>39654</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>去</th>\n",
       "      <td>34901</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>在</th>\n",
       "      <td>32626</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>有</th>\n",
       "      <td>28918</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>仪象</th>\n",
       "      <td>1</td>\n",
       "      <td>100488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>当说</th>\n",
       "      <td>1</td>\n",
       "      <td>100489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>夜梦</th>\n",
       "      <td>1</td>\n",
       "      <td>100490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>寂寂</th>\n",
       "      <td>1</td>\n",
       "      <td>100491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>日增</th>\n",
       "      <td>1</td>\n",
       "      <td>100492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>同時</th>\n",
       "      <td>1</td>\n",
       "      <td>100493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>逛物</th>\n",
       "      <td>1</td>\n",
       "      <td>100494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>香酥</th>\n",
       "      <td>1</td>\n",
       "      <td>100495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>恶露</th>\n",
       "      <td>1</td>\n",
       "      <td>100496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>乌石港</th>\n",
       "      <td>1</td>\n",
       "      <td>100497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100497 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      id\n",
       "，    364269       1\n",
       "的    210455       2\n",
       "。    123441       3\n",
       "      72410       4\n",
       "了     56857       5\n",
       "是     54971       6\n",
       "很     39654       7\n",
       "去     34901       8\n",
       "在     32626       9\n",
       "有     28918      10\n",
       "..      ...     ...\n",
       "仪象        1  100488\n",
       "当说        1  100489\n",
       "夜梦        1  100490\n",
       "寂寂        1  100491\n",
       "日增        1  100492\n",
       "同時        1  100493\n",
       "逛物        1  100494\n",
       "香酥        1  100495\n",
       "恶露        1  100496\n",
       "乌石港       1  100497\n",
       "\n",
       "[100497 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sent = lambda x: list(dict['id'][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['sent'] = train['words'].apply(get_sent) #速度太慢\n",
    "predict['sent'] = predict['words'].apply(get_sent) #速度太慢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n"
     ]
    }
   ],
   "source": [
    "print(\"Pad sequences (samples x time)\")\n",
    "train['sent'] = list(sequence.pad_sequences(train['sent'], maxlen=maxlen))\n",
    "predict['sent'] = list(sequence.pad_sequences(predict['sent'], maxlen=maxlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  205,    82,   294,     2,  1467,  2662, 92063,     1,   139,\n",
       "         112], dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['sent'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(list(train['sent']))[::2] #训练集\n",
    "y_ = np.array(y)[::2]\n",
    "\n",
    "xt = np.array(list(train['sent']))[1::2] #测试集\n",
    "yt = np.array(y)[1::2]\n",
    "\n",
    "x_sub = np.array(list(predict['sent'])) #提交集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   35, 23043,  3083, ...,     1, 14236,     2],\n",
       "       [  205,    82,   294, ...,     1,   139,   112],\n",
       "       [    0,     0,     0, ...,     0,  1647,   548],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,     0,    16,    12],\n",
       "       [ 2882,   712,     7, ...,     2,    30,     3],\n",
       "       [  127,  3519,   116, ...,   256,   108,   159]], dtype=int32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(dict) + 1, 256))\n",
    "model.add(LSTM(256)) # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.fit(x, y_, batch_size=32, nb_epoch=2,validation_data=(xt,yt)) #训练时间为若干个小时\n",
    "\n",
    "y_test = [np.argmax(i) for i in list(yt)]\n",
    "v = pd.DataFrame()\n",
    "v['result'] = list(y_test)\n",
    "v['true'] = list(model.predict_classes(xt,batch_size=32))\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.random.rand(2,3)<0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True],\n",
       "       [False,  True,  True]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=np.random.rand(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17114804, 0.27230914, 0.8840475 ],\n",
       "       [0.89157913, 0.02448434, 0.81999735]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17114804, 0.27230914, 0.8840475 ],\n",
       "       [0.        , 0.02448434, 0.81999735]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21393505, 0.34038642, 1.10505938],\n",
       "       [0.        , 0.03060543, 1.02499669]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(a,b)/0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
